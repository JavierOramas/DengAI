{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   }
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "import math\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range = (0, 1))\n",
    "\n",
    "dataframe=pd.read_csv('Data/dengue_features_train.csv')\n",
    "labels=pd.read_csv('Data/dengue_labels_train.csv')\n",
    "target_df=pd.read_csv('Data/dengue_features_test.csv')\n",
    "submission_format=pd.read_csv('Data/submission_format.csv')\n",
    "#target_df['month']=[int(i[5:7]) for i in target_df['week_start_date']]\n",
    "\n",
    "def clean_data(df):\n",
    "    #file.set_index('week_start_date', drop = True, inplace = True)\n",
    "    #df['month']=[int(i[5:7]) for i in df['week_start_date']]\n",
    "    #df['nvdi']= df['ndvi_ne']+df['ndvi_nw']+df['ndvi_se']+df['ndvi_sw']\n",
    "    \n",
    "    df=df.drop(['city','week_start_date', 'year' ], axis = 1, inplace = True)\n",
    "    \n",
    "    #,'ndvi_ne','ndvi_nw', 'ndvi_se', 'ndvi_sw', 'reanalysis_tdtr_k', 'precipitation_amt_mm', 'reanalysis_sat_precip_amt_mm','reanalysis_max_air_temp_k'\n",
    "\n",
    "def fill_missing_values(df):\n",
    "    imputer = SimpleImputer(strategy=\"median\") \n",
    "    imputer.fit(df)\n",
    "    x=imputer.transform(df)\n",
    "   \n",
    "    return pd.DataFrame(x, columns=df.columns)\n",
    "\n",
    "def split_data_in_cities(df):\n",
    "    #cities=set(df['city'])\n",
    "    cities=['sj','iq']\n",
    "    new_files=[]\n",
    "    for city in list(cities):\n",
    "        new_files.append(df[df['city'] == city])\n",
    "\n",
    "    return new_files\n",
    "\n",
    "def eliminate_not_outliers(df_labels, city_df):\n",
    "    cases=np.array(df_labels['total_cases'])\n",
    "    df_labels=df_labels.reset_index()\n",
    "    city_df=city_df.reset_index()\n",
    "    rows_to_eliminate=[]\n",
    "    mean=cases.mean()\n",
    "    for i in range(len(cases)):\n",
    "        if(cases[i]<(mean+20)):\n",
    "            rows_to_eliminate.append(i)\n",
    "    \n",
    "    #print(rows_to_eliminate)\n",
    "    #print(df_labels)\n",
    "    df_labels.drop(rows_to_eliminate, axis=0, inplace=True)\n",
    "    city_df.drop(rows_to_eliminate, axis=0, inplace=True)\n",
    "    df_labels.drop(['index'], axis=1, inplace=True)\n",
    "    city_df.drop(['index'], axis=1, inplace=True)\n",
    "    return df_labels, city_df\n",
    "\n",
    "def preprocess_data(df):\n",
    "    clean_data(df)\n",
    "    df=fill_missing_values(df)\n",
    "    return df\n",
    "\n",
    "def save_submission(first_prediction, second_prediction, name_of_file):\n",
    "    solution=list(first_prediction)\n",
    "    for x in second_prediction:\n",
    "        solution.append(x)\n",
    "        \n",
    "    solution=np.array(solution)\n",
    "    solution=np.int64(np.round(solution))\n",
    "    submission_format['total_cases']=pd.DataFrame(solution)[0]\n",
    "    submission_format.to_csv(name_of_file, index=False)\n",
    "    \n",
    "    \n",
    "new_files=split_data_in_cities(dataframe)\n",
    "new_labels=split_data_in_cities(labels)\n",
    "new_target=split_data_in_cities(target_df)\n",
    "\n",
    "sj_df=new_files[0]\n",
    "iq_df=new_files[1]\n",
    "\n",
    "sj_labels=new_labels[0]\n",
    "iq_labels=new_labels[1]\n",
    "\n",
    "sj_target=new_target[0]\n",
    "iq_target=new_target[1]\n",
    "\n",
    "sj_df=preprocess_data(sj_df)\n",
    "iq_df=preprocess_data(iq_df)\n",
    "sj_target=preprocess_data(sj_target)\n",
    "iq_target=preprocess_data(iq_target)\n",
    "#clean_data(sj_df)\n",
    "#clean_data(iq_df)\n",
    "#sj_labels, sj_df =eliminate_not_outliers(sj_labels, sj_df)\n",
    "#iq_labels, iq_df= eliminate_not_outliers(iq_labels, iq_df)\n",
    "\n",
    "#sj_df=fill_missing_values(sj_df)\n",
    "#iq_df=fill_missing_values(iq_df)\n",
    "\n",
    "#clean_data(dataframe)\n",
    "#dataframe=fill_missing_values(dataframe)\n",
    "\n",
    "sj_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "regression_models = [RandomForestRegressor(),\n",
    "                     ExtraTreesRegressor()]\n",
    "\n",
    "names = [\"RandomForestRegressor\",\n",
    "         \"ExtraTreesRegressor\"]\n",
    "\n",
    "complexity_evaluator = ComplexityEvaluator.ComplexityEvaluator(\n",
    "    [500, 1000, 2000, 5000],\n",
    "    [5, 10, 20, 50, 100, 200])\n",
    "\n",
    "i = 0\n",
    "for model in regression_models:\n",
    "    res, data = complexity_evaluator.Run(model, random_data_regression)\n",
    "    print(names[i])\n",
    "    print tabulate(data, headers='keys', tablefmt='psql', showindex='never')\n",
    "    i = i + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}